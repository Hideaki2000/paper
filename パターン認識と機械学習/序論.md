@import "../local.less"

# 序論

## 確率の基本法則

**加法定理**
$$\begin{equation}
  p(X)=\sum_Yp(X,Y)
\end{equation}$$

**乗法定理**

$$\begin{equation}
  p(X,Y)=p(Y|X)p(X)
\end{equation}$$


**ベイズの定理**

$$\begin{equation}
  p(Y|X)=\frac{p(X|Y)p(Y)}{p(X)}
\end{equation}$$

## 事前確率と事後確率

**事前確率**
観測するより事前に得られる確率値

**事後確率**
観測した事後の確率

## ベイズの定理と多項式フィッティング

データを観測する前にあらかじめ$\boldsymbol{w}$に関する我々の仮説を事前確率分布$p(\boldsymbol{w})$の形で取り込んでおく、観測データ$D=\{t_1,\ldots t_N\}$の効果は$p(D|\boldsymbol{w})$という条件確立で表現される。ここでベイズの定理は
$$\begin{equation}
  p(\boldsymbol{w}|D)=\frac{p(D|\boldsymbol{w})p(\boldsymbol{w})}{p(D)}
\end{equation}$$
という形をとり、$D$を観測した事後に$\boldsymbol{w}$に関する不確実性を事後分布$p(\boldsymbol{w}|D)$の形で評価することを可能とする。
<em class="imp">ベイズの定理を用いることで条件つき確率を逆にすることができる。</em>

## 決定理論

確率論が、不確実性を定量化したり操作するための一貫した数学的枠組みを与えることをみた。決定理論は確率論と組み合わせることによって、パターン認識で遭遇する、不確かさを含む状況における最適な意思決定を行うことができる。

例として、医療診断問題の例を考える。患者のx線画像をとり、その患者が癌であるかどうかを判定したいとしよう、この場合、入力ベクトル$\bold{x}$は画像のピクセル強度の集合で、出力変数tは癌であるクラス$C_1$か、癌でないクラス$C_2$のどちらかを表す。ここで、例えば$t$として2値変数を選び、$t=0$がクラス$C_1$,$t=1$がクラス$C_2$に対応する。今回の目標として新たな患者のx線画像$\bold{x}$が得られた時、画像に二つのクラスのどちらかを割り当てることが目標である。与えられた画像に対し、２つのクラスの確率$p(C_k|\bold{x})$を求めたい、ベイズの定理を使うと、これらの確率は

$$p(C_k|\bold{x})=\frac{p(\bold{x}|C_k)p(C_k)}{p(\bold{x})}$$と表せられる。
すなわち、$p(C_1)$はx線を計測する前に人間が癌である確率、$p(\bold{x})$その画像が得られる確率、

## 誤識別率の最小化


